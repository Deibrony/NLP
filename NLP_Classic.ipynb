{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Classic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnQSaIp5ZzKp"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "\n",
        "import nltk\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 120\n",
        "from sklearn import preprocessing\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs7p_mDiZPe8",
        "outputId": "859aa1a0-90cf-4521-89a3-f8feaf568a64"
      },
      "source": [
        "!unzip -q //content/drive/MyDrive/datasets/IMDBDataset.csv.zip\n",
        "!ls\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace IMDB Dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  drive\t'IMDB Dataset.csv'   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sITyttlGZlOA",
        "outputId": "50d74154-1001-4167-8b39-b0d27172d53a"
      },
      "source": [
        "df = pd.read_csv('/content/IMDB Dataset.csv', encoding='latin-1')\n",
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou7yiAnG9qmm"
      },
      "source": [
        "def clean(text):\n",
        "    text = text.lower() #привод к нижнему регистру\n",
        "    text = re.sub(r'http\\S+', \" \", text) #\n",
        "    text = re.sub(r'@\\w+',' ',text) #\n",
        "    text = re.sub(r'#\\w+', ' ', text) #\n",
        "    text = re.sub(r'\\d+', ' ', text) #\n",
        "    text = re.sub(r'<.*?>',' ', text) #\n",
        "    return text"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXfU-_DNaDy2",
        "outputId": "5b8e97f5-8010-4f59-b3a2-209157393c29"
      },
      "source": [
        "len(df) ,df.isnull().sum()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, review       0\n",
              " sentiment    0\n",
              " dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgbVfYeVb-aW",
        "outputId": "e0ffca9a-4605-4710-cc9b-9445f778405e"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit_transform(df['review'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29427,  3472, 19496, ..., 12485, 21422, 27736])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTreZLNX9_4e",
        "outputId": "3ada44cf-09c1-4907-8630-5d2d0a12b0eb"
      },
      "source": [
        "text = df['review']\n",
        "text.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    One of the other reviewers has mentioned that ...\n",
              "1    A wonderful little production. <br /><br />The...\n",
              "2    I thought this was a wonderful way to spend ti...\n",
              "3    Basically there's a family where a little boy ...\n",
              "4    Petter Mattei's \"Love in the Time of Money\" is...\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X3tYIbZ-Li1",
        "outputId": "28e3c78f-7ab9-4829-d622-e58fc131689b"
      },
      "source": [
        "text = text.apply(clean)\n",
        "text.head(15)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     one of the other reviewers has mentioned that ...\n",
              "1     a wonderful little production.   the filming t...\n",
              "2     i thought this was a wonderful way to spend ti...\n",
              "3     basically there's a family where a little boy ...\n",
              "4     petter mattei's \"love in the time of money\" is...\n",
              "5     probably my all-time favorite movie, a story o...\n",
              "6     i sure would like to see a resurrection of a u...\n",
              "7     this show was an amazing, fresh & innovative i...\n",
              "8     encouraged by the positive comments about this...\n",
              "9     if you like original gut wrenching laughter yo...\n",
              "10    phil the alien is one of those quirky films wh...\n",
              "11    i saw this movie when i was about   when it ca...\n",
              "12    so im not a big fan of boll's work but then ag...\n",
              "13    the cast played shakespeare.  shakespeare lost...\n",
              "14    this a fantastic movie of three prisoners who ...\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s4FscFf-4PZ"
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBrySDo6-7O7"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4mRJ8Ag-7tD"
      },
      "source": [
        "wn_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNGD5mBX_Sm-",
        "outputId": "6038a428-a74b-4f79-e5e8-b9a65eda6872"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DndRYy2m_J-v"
      },
      "source": [
        "dirty_tweet = text.iloc[520]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NTUyxjt_NDZ",
        "outputId": "fb0cea8b-9096-4376-a7bb-7dc0a947374c"
      },
      "source": [
        "print(f'''\n",
        "      ** Original Tweet **: \\n \\n      \n",
        "      {dirty_tweet}\n",
        "      \n",
        "      ------------------------------------------------\n",
        "      \n",
        "      ** WordNetLemmatizer: ** \\n \\n\n",
        "      {' '.join([wn_lemmatizer.lemmatize(word) for word in dirty_tweet.split()])}\n",
        "      ''')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      ** Original Tweet **: \n",
            " \n",
            "      \n",
            "      i am a huge fan of the farcry game, huge fan. it still holds a place in my top-  games list of all time! the story line was new, fresh... a truly brilliant foundation to base a movie on... or so i thought...  farcry the movie is no less than another directors attempt at cashing in on a successful game franchise (see doom: the movie, and many more...).  the video game begins as the player (jack carver) awakes in a sea side cave after been shot off his boat by an rpg from an unknown soldier. jack then finds a communication device where (harlan doyle) guides him across islands, shipwrecks, jungles, installations and volcanoes, to find his (lady friend?) (valerie constantine), all the wile battling mutated super soldiers, and genetically enhanced animals.  the movie plays out very, very differently:  : there's a needless   mins ( /  of the movie) of \"backstory\" before we even get to the 'boat blowing up' scene.  : jack then walks onto the beach, kills some goons, then drives off... nothing like the game...  : there is no communicator with doyle on the other end...  : the 'modified soldiers' look like albinos with singlets on... and there was no mutated 'monkey-like' creatures jumping out of the bushes. a part of the farcry game i enjoyed allot...  : there is no sun filled beach scenes, no aircraft carrier, no communications stations on huge cliffs, little reference to any in-game contents (characters/items/vehicles), in fact no attempt to follow the story line at all.  : the climactic volcano scene from the game is replaced with an old industrial building.  : there's an ending scene... where everyone (except krieger) live happily ever after... what the!  i recommend avoiding this movie at all costs! if you are a gamer, you will hate this movie will all your soul. it is a movie clearly intended for males, so girls, stay away... so if your a male,  -  years of age, have never played farcry, and are not disgusted by directors attempts at porting books/games to the cinema... then this is for you...\n",
            "      \n",
            "      ------------------------------------------------\n",
            "      \n",
            "      ** WordNetLemmatizer: ** \n",
            " \n",
            "\n",
            "      i am a huge fan of the farcry game, huge fan. it still hold a place in my top- game list of all time! the story line wa new, fresh... a truly brilliant foundation to base a movie on... or so i thought... farcry the movie is no le than another director attempt at cashing in on a successful game franchise (see doom: the movie, and many more...). the video game begin a the player (jack carver) awakes in a sea side cave after been shot off his boat by an rpg from an unknown soldier. jack then find a communication device where (harlan doyle) guide him across islands, shipwrecks, jungles, installation and volcanoes, to find his (lady friend?) (valerie constantine), all the wile battling mutated super soldiers, and genetically enhanced animals. the movie play out very, very differently: : there's a needle min ( / of the movie) of \"backstory\" before we even get to the 'boat blowing up' scene. : jack then walk onto the beach, kill some goons, then drive off... nothing like the game... : there is no communicator with doyle on the other end... : the 'modified soldiers' look like albino with singlet on... and there wa no mutated 'monkey-like' creature jumping out of the bushes. a part of the farcry game i enjoyed allot... : there is no sun filled beach scenes, no aircraft carrier, no communication station on huge cliffs, little reference to any in-game content (characters/items/vehicles), in fact no attempt to follow the story line at all. : the climactic volcano scene from the game is replaced with an old industrial building. : there's an ending scene... where everyone (except krieger) live happily ever after... what the! i recommend avoiding this movie at all costs! if you are a gamer, you will hate this movie will all your soul. it is a movie clearly intended for males, so girls, stay away... so if your a male, - year of age, have never played farcry, and are not disgusted by director attempt at porting books/games to the cinema... then this is for you...\n",
            "      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77YIjJ1tAt1w"
      },
      "source": [
        "lemmatized_text = []\n",
        "for tweet in text:\n",
        "    lemmatized_text.append(' '.join([wn_lemmatizer.lemmatize(word) for word in tweet.split()]))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDxPJJ38BUrX"
      },
      "source": [
        "reg_tokenizer = RegexpTokenizer('\\w+')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHfjC0H9BY6t"
      },
      "source": [
        "tokenized_text = reg_tokenizer.tokenize_sents(lemmatized_text)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfjppcg3BdQi",
        "outputId": "45768c4f-7a49-450b-8ce8-ea766fd750ca"
      },
      "source": [
        "len(tokenized_text)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OCypWztBknh",
        "outputId": "45aebf18-68f2-4437-ecc2-aa5482814c52"
      },
      "source": [
        "  >>> import nltk\n",
        "  >>> nltk.download('stopwords')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDvBMSM9Bexu"
      },
      "source": [
        "sw = stopwords.words()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enBumIrwBnqa",
        "outputId": "635b90cf-eeac-418a-8712-b31a1bc49175"
      },
      "source": [
        "clean_tokenized_tweets = [] \n",
        "for i, element in enumerate(tokenized_text):\n",
        "    if i % 2000 == 0: print(i, end = ' ')\n",
        "    clean_tokenized_tweets.append(' '.join([word for word in element if word not in sw]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 2000 4000 6000 8000 10000 12000 14000 16000 18000 20000 22000 24000 26000 28000 30000 32000 34000 36000 38000 40000 42000 44000 46000 48000 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9YDTzpD0NJ"
      },
      "source": [
        "df = pd.concat([pd.Series(clean_tokenized_tweets, name='review'), \n",
        "                pd.Series(df['sentiment'], name='sentiment')], \n",
        "               axis=1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "S-Q9lGgLEbjq",
        "outputId": "4cce43ca-e60b-43d5-a1a8-9d685ee5c5c9"
      },
      "source": [
        "df['review'][3]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'basically family little boy jake think zombie closet parent fighting time movie slower soap opera suddenly jake decides become rambo kill zombie ok first going make film must decide thriller drama drama movie watchable parent divorcing arguing like real life jake closet totally ruin film expected see boogeyman similar movie instead watched drama meaningless thriller spots well playing parent descent dialogs shot jake ignore'"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-nrY4qZEGVN"
      },
      "source": [
        "df.to_csv('clean_review', index=False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64gqIeQuEXel"
      },
      "source": [
        "`CountVectorizer`: make **bag of words** representation \n",
        "\n",
        "`TfidfVectorizer`: make **frequency based** representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znoCcvQlESN5"
      },
      "source": [
        "# Create objects\n",
        "cvec = CountVectorizer(ngram_range=(1, 2))\n",
        "tfid = TfidfVectorizer(ngram_range=(1, 2))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaRs5aDjEwyu"
      },
      "source": [
        "cvec_representation = cvec.fit_transform(pd.Series(clean_tokenized_tweets))\n",
        "tfid_representation = tfid.fit_transform(pd.Series(clean_tokenized_tweets))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhEt7w8IEzaM"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNWTYzwVFmL8"
      },
      "source": [
        "mnb = MultinomialNB()\n",
        "lrc = LogisticRegression()\n",
        "svc = SVC()\n",
        "ls=Lasso()\n",
        "sgd=SGDClassifier()\n",
        "rf=RandomForestClassifier()\n",
        "sgd=SGDClassifier"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6d6j-k4Foxe"
      },
      "source": [
        "clfs = {\n",
        "    'MultiNB' : mnb, \n",
        "   # 'LogisticRegression' : lrc,\n",
        "     \n",
        "   #  'SGDClassifier': sgd\n",
        "\n",
        "}"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GV5nT-XF1Bd"
      },
      "source": [
        "def get_scores(clfs, n_cv=2):\n",
        "    for clf in clfs: \n",
        "        cvec_scores = cross_val_score(clfs[clf], cvec_representation, df['sentiment'], n_jobs=4, cv=n_cv, scoring='accuracy')\n",
        "        tfidf_scores = cross_val_score(clfs[clf], tfid_representation,  df['sentiment'], n_jobs=4, cv=n_cv, scoring='accuracy')\n",
        "\n",
        "        cvec_mean_score, cvec_std_score = np.mean(cvec_scores), np.std(cvec_scores)\n",
        "        tfidf_mean_score, tfidf_std_score = np.mean(tfidf_scores), np.std(tfidf_scores)\n",
        "        print(f''' \n",
        "        {clf}\n",
        "        CountVectorizer score: {cvec_mean_score:.3f}, std: {cvec_std_score:.3f}\n",
        "        TfIdf score: {tfidf_mean_score:.3f}, std: {tfidf_std_score:.3f}\n",
        "        ''')\n",
        "        "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_DDLI-sG2Sp",
        "outputId": "917f1de5-4d30-4178-98d4-73fc13eb9cd0"
      },
      "source": [
        "get_scores(clfs, 2)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "        MultiNB\n",
            "        CountVectorizer score: 0.879, std: 0.000\n",
            "        TfIdf score: 0.882, std: 0.002\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uafZy0MSn46v"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms3ZDe9CJqCP"
      },
      "source": [
        "df = pd.read_csv('/content/IMDB Dataset.csv', encoding='latin-1')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbMiNpetn7o7"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZffeS2zWoBHI"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.parsing.preprocessing import STOPWORDS # more stopwords in gensim corpus\n",
        " \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# nltk.download('wordnet')\n",
        "import re\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "stop_nltk = stopwords.words('english') # nltk corpus\n",
        "\n",
        "STOPWORDS = STOPWORDS.union(set([\"don't\", \"i'm\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYh7Yi4xoB6N"
      },
      "source": [
        "y = df['sentiment'].replace({'Negative' : 0, \n",
        "                                 'Positive' : 1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNFHoeuuoRCP"
      },
      "source": [
        "reg_tok = RegexpTokenizer('\\w+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wskIadF8oThI"
      },
      "source": [
        "def clean_and_lemmatize(text):\n",
        "    #cleaning\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+', \" \", text)\n",
        "    text = re.sub(r'@\\w+',' ',text)\n",
        "    text = re.sub(r'#\\w+', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    text = re.sub('r<.*?>',' ', text)\n",
        "    text = reg_tok.tokenize(text)\n",
        "    \n",
        "    \n",
        "    # filtering\n",
        "    text = \" \".join([word for word in text if not word in STOPWORDS and len(word) > 2])\n",
        "    \n",
        "    # lemmatization\n",
        "    text = WordNetLemmatizer().lemmatize(text)\n",
        "    text = text.split()\n",
        "    \n",
        "    \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EJTT2ByoYCx"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mGW2RVnob98"
      },
      "source": [
        "preprocessed_tweets = df['review'].apply(clean_and_lemmatize)\n",
        "preprocessed_tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngMP-0XLoeEQ"
      },
      "source": [
        "len(preprocessed_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU0gbbPHoisv"
      },
      "source": [
        "wv = Word2Vec(min_count=20,\n",
        "              window=3,\n",
        "              size=400, \n",
        "              workers=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLIgRix0olBZ"
      },
      "source": [
        "import gensim\n",
        "gensim.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoi4PUMyonDP"
      },
      "source": [
        "wv.build_vocab(preprocessed_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdOYlbUPoq4J"
      },
      "source": [
        "# train model\n",
        "wv.train(preprocessed_tweets, \n",
        "         total_examples=len(preprocessed_tweets), \n",
        "         epochs=20, \n",
        "         queue_factor=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBNfEmK3orsw"
      },
      "source": [
        "X = wv[wv.wv.vocab]\n",
        "words = list(wv.wv.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqwyOoZyotuh"
      },
      "source": [
        "X_embed = TSNE(n_iter=500).fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFNLmoVQoxW8"
      },
      "source": [
        "plt.figure(figsize=(18, 8))\n",
        "plt.scatter(X_embed[:60, 0], X_embed[:60, 1])\n",
        "annotations = []\n",
        "for i, word in enumerate(words[:60]):\n",
        "    annotations.append(plt.annotate(word, xy=(X_embed[i, 0]+.05, X_embed[i, 1]), fontsize=9, alpha=.5, ))\n",
        "adjust_text(annotations)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}